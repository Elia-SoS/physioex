{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/guidogagl/physioex/blob/main/examples/colab_setup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TJehO5FpB8Lw",
    "outputId": "b0940395-9d4f-4646-87dc-6726b9235cfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# mount your personal gdrive folder inside google colab server\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def download_mitdb():\n",
    "    home_dir = os.path.expanduser(\"~\")\n",
    "    mitdb_dir = os.path.join(home_dir, \"mitdb\")\n",
    "    if not os.path.exists(mitdb_dir):\n",
    "        os.makedirs(mitdb_dir)\n",
    "\n",
    "    # Cambia la directory di lavoro corrente alla cartella CINC\n",
    "    current_dir = os.getcwd()\n",
    "    os.chdir(mitdb_dir)\n",
    "\n",
    "    # Download the dataset into the current working dir using wfdb\n",
    "    wfdb.dl_database(\"mitdb\", os.getcwd())\n",
    "\n",
    "    print(\"Dataset downloaded.\")\n",
    "    os.chdir(current_dir)\n",
    "\n",
    "\n",
    "download_mitdb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal MLII not found in subject 102.\n",
      "Available signals are: ['V5', 'V2']\n",
      "Signal MLII not found in subject 104.\n",
      "Available signals are: ['V5', 'V2']\n"
     ]
    }
   ],
   "source": [
    "import wfdb\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "mitdb_dir = \"/home/guido/mitdb\"\n",
    "\n",
    "pick = \"MLII\"\n",
    "subjects = [\n",
    "    int(f.split(\".\")[0])\n",
    "    for f in os.listdir(mitdb_dir)\n",
    "    if os.path.isfile(os.path.join(mitdb_dir, f))\n",
    "]\n",
    "# get the integer part of the file name\n",
    "subjects = np.unique(subjects).astype(int)\n",
    "\n",
    "for subject in subjects:\n",
    "    samp = wfdb.rdsamp(f\"{mitdb_dir}/{subject}\")\n",
    "    annt = wfdb.rdann(f\"{mitdb_dir}/{subject}\", \"atr\")\n",
    "\n",
    "    try:\n",
    "        signal = samp[0][:, samp[1][\"sig_name\"].index(pick)]\n",
    "    except:\n",
    "        print(f\"Signal {pick} not found in subject {subject}.\")\n",
    "        print(f\"Available signals are: {samp[1]['sig_name']}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedGroupKFold(n_splits=3, random_state=42, shuffle=True)\n",
      "Fold 0:\n",
      "  Train: index=[ 0  1  2  3  7 12 13 14]\n",
      "         group=[1 1 2 2 4 6 6 7]\n",
      "  Test:  index=[ 4  5  6  8  9 10 11 15 16]\n",
      "         group=[3 3 3 5 5 5 5 8 8]\n",
      "Fold 1:\n",
      "  Train: index=[ 4  5  6  8  9 10 11 12 13 14 15 16]\n",
      "         group=[3 3 3 5 5 5 5 6 6 7 8 8]\n",
      "  Test:  index=[0 1 2 3 7]\n",
      "         group=[1 1 2 2 4]\n",
      "Fold 2:\n",
      "  Train: index=[ 0  1  2  3  4  5  6  7  8  9 10 11 15 16]\n",
      "         group=[1 1 2 2 3 3 3 4 5 5 5 5 8 8]\n",
      "  Test:  index=[12 13 14]\n",
      "         group=[6 6 7]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "X = np.ones((17, 2))\n",
    "y = np.array([0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "groups = np.array([1, 1, 2, 2, 3, 3, 3, 4, 5, 5, 5, 5, 6, 6, 7, 8, 8])\n",
    "sgkf = StratifiedGroupKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "sgkf.get_n_splits(X, y)\n",
    "print(sgkf)\n",
    "for i, (train_index, test_index) in enumerate(sgkf.split(X, y, groups)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"         group={groups[train_index]}\")\n",
    "    print(f\"  Test:  index={test_index}\")\n",
    "    print(f\"         group={groups[test_index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[203, 116, 106, 112]\n",
      "[101, 108, 109, 114, 115, 118, 119, 122, 124, 201, 205, 207, 208, 209, 215, 220, 223, 230]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "train_ids = [\n",
    "    101,\n",
    "    106,\n",
    "    108,\n",
    "    109,\n",
    "    112,\n",
    "    114,\n",
    "    115,\n",
    "    116,\n",
    "    118,\n",
    "    119,\n",
    "    122,\n",
    "    124,\n",
    "    201,\n",
    "    203,\n",
    "    205,\n",
    "    207,\n",
    "    208,\n",
    "    209,\n",
    "    215,\n",
    "    220,\n",
    "    223,\n",
    "    230,\n",
    "]\n",
    "# select 20% of the subjects as valid subjects\n",
    "valid_ids = random.sample(train_ids, int(0.2 * len(train_ids)))\n",
    "\n",
    "train_ids = [subject for subject in train_ids if subject not in valid_ids]\n",
    "\n",
    "print(valid_ids)\n",
    "print(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100 101 102 103 104 105 106 107 108 109 111 112 113 114 115 116 117 118\n",
      " 119 121 122 123 124 200 201 202 203 205 207 208 209 210 212 213 214 215\n",
      " 217 219 220 221 222 223 228 230 231 232 233 234]\n",
      "[119 220 106 232 100 230 234 109 213 118 114 113 101 105 231 124 200 228\n",
      " 205 214 223 215 208 121 203 111 112 123 108 122 116 221 212 233 117 107\n",
      " 217 103 201 210 222 207 115 202 209 219]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import yaml\n",
    "\n",
    "# import KFold from sklearn\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Ottieni l'elenco di tutti i file nella directory\n",
    "all_files = os.listdir(\"/home/guido/mitdb\")\n",
    "\n",
    "# Rimuovi le estensioni dei file per ottenere solo gli ID dei soggetti\n",
    "all_ids = [os.path.splitext(file)[0] for file in all_files]\n",
    "all_ids = np.unique(all_ids).astype(int)\n",
    "print(all_ids)\n",
    "# Mescola gli ID dei soggetti\n",
    "# remove subject 102 and 104 from the ids\n",
    "all_ids = sorted(np.array([id for id in all_ids if id not in [102, 104]]).tolist())\n",
    "\n",
    "# esegui una 10-cross fold degli id\n",
    "split = {\"subjects\": all_ids.copy(), \"split\": {}}\n",
    "\n",
    "random.shuffle(all_ids)\n",
    "all_ids = np.array(all_ids)\n",
    "print(all_ids)\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "for i, (train_index, test_index) in enumerate(kf.split(all_ids)):\n",
    "    train_ids = all_ids[train_index]\n",
    "    test_ids = all_ids[test_index]\n",
    "\n",
    "    # estrai randomicamente gli elementi di validazione dal training set\n",
    "    # in numero uguale agli elementi di testing e rimuovili dal set di training\n",
    "\n",
    "    valid_ids = np.array(random.sample(train_ids.tolist(), len(test_ids)))\n",
    "    train_ids = np.array([id for id in train_ids if id not in valid_ids])\n",
    "\n",
    "    fold = {\n",
    "        \"train\": train_ids.tolist(),\n",
    "        \"test\": test_ids.tolist(),\n",
    "        \"valid\": valid_ids.tolist(),\n",
    "    }\n",
    "\n",
    "    split[\"split\"][f\"fold_{i}\"] = fold\n",
    "\n",
    "# convert split into a dictonary and dave it as yaml file\n",
    "\n",
    "\n",
    "# Save the dictionary as a YAML file\n",
    "with open(\"split.yaml\", \"w\") as file:\n",
    "    yaml.dump(split, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guido/miniconda3/envs/physioex/lib/python3.10/site-packages/braindecode/preprocessing/preprocess.py:55: UserWarning: Preprocessing choices with lambda functions cannot be saved.\n",
      "  warn('Preprocessing choices with lambda functions cannot be saved.')\n",
      "\u001b[32m2024-03-23 19:32:26.445\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mphysioex.data.mitdb\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m130\u001b[0m - \u001b[1mFetching the dataset..\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-23 19:32:29.697\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mphysioex.data.mitdb\u001b[0m:\u001b[36mload_signal\u001b[0m:\u001b[36m105\u001b[0m - \u001b[1mClass distribution: Counter({0: 31528, 2: 1587, 1: 746, 3: 260, 4: 4})\u001b[0m\n",
      "\u001b[32m2024-03-23 19:32:29.728\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mphysioex.data.utils\u001b[0m:\u001b[36mwrite_cache\u001b[0m:\u001b[36m54\u001b[0m - \u001b[1mCaching dataset into temp/mitdb.pkl\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720\n",
      "720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-23 19:32:32.447\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mphysioex.data.mitdb\u001b[0m:\u001b[36msplit\u001b[0m:\u001b[36m183\u001b[0m - \u001b[1mTrain shape X (26770, 1, 720), y (26770,)\u001b[0m\n",
      "\u001b[32m2024-03-23 19:32:32.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mphysioex.data.mitdb\u001b[0m:\u001b[36msplit\u001b[0m:\u001b[36m184\u001b[0m - \u001b[1mValid shape X (3765, 1, 720), y (3765,)\u001b[0m\n",
      "\u001b[32m2024-03-23 19:32:32.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mphysioex.data.mitdb\u001b[0m:\u001b[36msplit\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mTest shape X (3590, 1, 720), y (3590,)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 720)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from physioex.data.mitdb import MITBIH\n",
    "\n",
    "db = MITBIH(use_cache=False)\n",
    "db.split(0)\n",
    "train, _, test = db.get_sets()\n",
    "\n",
    "train[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-23 19:24:14.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mphysioex.data.mitdb\u001b[0m:\u001b[36msplit\u001b[0m:\u001b[36m174\u001b[0m - \u001b[1mTrain shape X (12996, 1, 1800), y (12996,)\u001b[0m\n",
      "\u001b[32m2024-03-23 19:24:14.181\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mphysioex.data.mitdb\u001b[0m:\u001b[36msplit\u001b[0m:\u001b[36m175\u001b[0m - \u001b[1mValid shape X (1805, 1, 1800), y (1805,)\u001b[0m\n",
      "\u001b[32m2024-03-23 19:24:14.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mphysioex.data.mitdb\u001b[0m:\u001b[36msplit\u001b[0m:\u001b[36m176\u001b[0m - \u001b[1mTest shape X (1805, 1, 1800), y (1805,)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.split(0)\n",
    "train, _, test = db.get_sets()\n",
    "\n",
    "train[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "class EpochEncoder(nn.Module):\n",
    "    def __init__(self, module_config) -> None:\n",
    "        super(EpochEncoder, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=module_config[\"in_channels\"],\n",
    "            out_channels=32,\n",
    "            kernel_size=10,\n",
    "            stride=5,\n",
    "        )\n",
    "        self.conv2 = nn.Conv1d(\n",
    "            in_channels=32, out_channels=16, kernel_size=10, stride=5\n",
    "        )\n",
    "        self.conv3 = nn.Conv1d(in_channels=16, out_channels=8, kernel_size=10, stride=5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.conv3(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "\n",
    "module_config = {\n",
    "    \"in_channels\": 1,\n",
    "}\n",
    "\n",
    "\n",
    "encoder = EpochEncoder(module_config)\n",
    "input_size = (batch_size, 1, 360 * 2)\n",
    "output = encoder(torch.zeros(input_size))\n",
    "output_size = output.size()\n",
    "\n",
    "print(output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdsamp -r 222 -c -H -f 0 -v >/home/guido/mitdb/csv/222.csv\n",
      "rdann -r 222 -f 0 -a atr -v >/home/guido/mitdb/csv/222annotations.txt\n",
      "rdsamp -r 113 -c -H -f 0 -v >/home/guido/mitdb/csv/113.csv\n",
      "rdann -r 113 -f 0 -a atr -v >/home/guido/mitdb/csv/113annotations.txt\n",
      "rdsamp -r 200 -c -H -f 0 -v >/home/guido/mitdb/csv/200.csv\n",
      "rdann -r 200 -f 0 -a atr -v >/home/guido/mitdb/csv/200annotations.txt\n",
      "rdsamp -r 202 -c -H -f 0 -v >/home/guido/mitdb/csv/202.csv\n",
      "rdann -r 202 -f 0 -a atr -v >/home/guido/mitdb/csv/202annotations.txt\n",
      "rdsamp -r 114 -c -H -f 0 -v >/home/guido/mitdb/csv/114.csv\n",
      "rdann -r 114 -f 0 -a atr -v >/home/guido/mitdb/csv/114annotations.txt\n",
      "rdsamp -r 104 -c -H -f 0 -v >/home/guido/mitdb/csv/104.csv\n",
      "rdann -r 104 -f 0 -a atr -v >/home/guido/mitdb/csv/104annotations.txt\n",
      "rdsamp -r 122 -c -H -f 0 -v >/home/guido/mitdb/csv/122.csv\n",
      "rdann -r 122 -f 0 -a atr -v >/home/guido/mitdb/csv/122annotations.txt\n",
      "rdsamp -r 109 -c -H -f 0 -v >/home/guido/mitdb/csv/109.csv\n",
      "rdann -r 109 -f 0 -a atr -v >/home/guido/mitdb/csv/109annotations.txt\n",
      "rdsamp -r 203 -c -H -f 0 -v >/home/guido/mitdb/csv/203.csv\n",
      "rdann -r 203 -f 0 -a atr -v >/home/guido/mitdb/csv/203annotations.txt\n",
      "rdsamp -r 119 -c -H -f 0 -v >/home/guido/mitdb/csv/119.csv\n",
      "rdann -r 119 -f 0 -a atr -v >/home/guido/mitdb/csv/119annotations.txt\n",
      "rdsamp -r 232 -c -H -f 0 -v >/home/guido/mitdb/csv/232.csv\n",
      "rdann -r 232 -f 0 -a atr -v >/home/guido/mitdb/csv/232annotations.txt\n",
      "rdsamp -r 107 -c -H -f 0 -v >/home/guido/mitdb/csv/107.csv\n",
      "rdann -r 107 -f 0 -a atr -v >/home/guido/mitdb/csv/107annotations.txt\n",
      "rdsamp -r 228 -c -H -f 0 -v >/home/guido/mitdb/csv/228.csv\n",
      "rdann -r 228 -f 0 -a atr -v >/home/guido/mitdb/csv/228annotations.txt\n",
      "rdsamp -r 215 -c -H -f 0 -v >/home/guido/mitdb/csv/215.csv\n",
      "rdann -r 215 -f 0 -a atr -v >/home/guido/mitdb/csv/215annotations.txt\n",
      "rdsamp -r 208 -c -H -f 0 -v >/home/guido/mitdb/csv/208.csv\n",
      "rdann -r 208 -f 0 -a atr -v >/home/guido/mitdb/csv/208annotations.txt\n",
      "rdsamp -r 219 -c -H -f 0 -v >/home/guido/mitdb/csv/219.csv\n",
      "rdann -r 219 -f 0 -a atr -v >/home/guido/mitdb/csv/219annotations.txt\n",
      "rdsamp -r 233 -c -H -f 0 -v >/home/guido/mitdb/csv/233.csv\n",
      "rdann -r 233 -f 0 -a atr -v >/home/guido/mitdb/csv/233annotations.txt\n",
      "rdsamp -r 117 -c -H -f 0 -v >/home/guido/mitdb/csv/117.csv\n",
      "rdann -r 117 -f 0 -a atr -v >/home/guido/mitdb/csv/117annotations.txt\n",
      "rdsamp -r 210 -c -H -f 0 -v >/home/guido/mitdb/csv/210.csv\n",
      "rdann -r 210 -f 0 -a atr -v >/home/guido/mitdb/csv/210annotations.txt\n",
      "rdsamp -r 124 -c -H -f 0 -v >/home/guido/mitdb/csv/124.csv\n",
      "rdann -r 124 -f 0 -a atr -v >/home/guido/mitdb/csv/124annotations.txt\n",
      "rdsamp -r 223 -c -H -f 0 -v >/home/guido/mitdb/csv/223.csv\n",
      "rdann -r 223 -f 0 -a atr -v >/home/guido/mitdb/csv/223annotations.txt\n",
      "rdsamp -r 230 -c -H -f 0 -v >/home/guido/mitdb/csv/230.csv\n",
      "rdann -r 230 -f 0 -a atr -v >/home/guido/mitdb/csv/230annotations.txt\n",
      "rdsamp -r 108 -c -H -f 0 -v >/home/guido/mitdb/csv/108.csv\n",
      "rdann -r 108 -f 0 -a atr -v >/home/guido/mitdb/csv/108annotations.txt\n",
      "rdsamp -r 213 -c -H -f 0 -v >/home/guido/mitdb/csv/213.csv\n",
      "rdann -r 213 -f 0 -a atr -v >/home/guido/mitdb/csv/213annotations.txt\n",
      "rdsamp -r 205 -c -H -f 0 -v >/home/guido/mitdb/csv/205.csv\n",
      "rdann -r 205 -f 0 -a atr -v >/home/guido/mitdb/csv/205annotations.txt\n",
      "rdsamp -r 111 -c -H -f 0 -v >/home/guido/mitdb/csv/111.csv\n",
      "rdann -r 111 -f 0 -a atr -v >/home/guido/mitdb/csv/111annotations.txt\n",
      "rdsamp -r 101 -c -H -f 0 -v >/home/guido/mitdb/csv/101.csv\n",
      "rdann -r 101 -f 0 -a atr -v >/home/guido/mitdb/csv/101annotations.txt\n",
      "rdsamp -r 217 -c -H -f 0 -v >/home/guido/mitdb/csv/217.csv\n",
      "rdann -r 217 -f 0 -a atr -v >/home/guido/mitdb/csv/217annotations.txt\n",
      "rdsamp -r 212 -c -H -f 0 -v >/home/guido/mitdb/csv/212.csv\n",
      "rdann -r 212 -f 0 -a atr -v >/home/guido/mitdb/csv/212annotations.txt\n",
      "rdsamp -r 106 -c -H -f 0 -v >/home/guido/mitdb/csv/106.csv\n",
      "rdann -r 106 -f 0 -a atr -v >/home/guido/mitdb/csv/106annotations.txt\n",
      "rdsamp -r 221 -c -H -f 0 -v >/home/guido/mitdb/csv/221.csv\n",
      "rdann -r 221 -f 0 -a atr -v >/home/guido/mitdb/csv/221annotations.txt\n",
      "rdsamp -r 118 -c -H -f 0 -v >/home/guido/mitdb/csv/118.csv\n",
      "rdann -r 118 -f 0 -a atr -v >/home/guido/mitdb/csv/118annotations.txt\n",
      "rdsamp -r 214 -c -H -f 0 -v >/home/guido/mitdb/csv/214.csv\n",
      "rdann -r 214 -f 0 -a atr -v >/home/guido/mitdb/csv/214annotations.txt\n",
      "rdsamp -r 121 -c -H -f 0 -v >/home/guido/mitdb/csv/121.csv\n",
      "rdann -r 121 -f 0 -a atr -v >/home/guido/mitdb/csv/121annotations.txt\n",
      "rdsamp -r 123 -c -H -f 0 -v >/home/guido/mitdb/csv/123.csv\n",
      "rdann -r 123 -f 0 -a atr -v >/home/guido/mitdb/csv/123annotations.txt\n",
      "rdsamp -r 231 -c -H -f 0 -v >/home/guido/mitdb/csv/231.csv\n",
      "rdann -r 231 -f 0 -a atr -v >/home/guido/mitdb/csv/231annotations.txt\n",
      "rdsamp -r 112 -c -H -f 0 -v >/home/guido/mitdb/csv/112.csv\n",
      "rdann -r 112 -f 0 -a atr -v >/home/guido/mitdb/csv/112annotations.txt\n",
      "rdsamp -r 209 -c -H -f 0 -v >/home/guido/mitdb/csv/209.csv\n",
      "rdann -r 209 -f 0 -a atr -v >/home/guido/mitdb/csv/209annotations.txt\n",
      "rdsamp -r 115 -c -H -f 0 -v >/home/guido/mitdb/csv/115.csv\n",
      "rdann -r 115 -f 0 -a atr -v >/home/guido/mitdb/csv/115annotations.txt\n",
      "rdsamp -r 102 -c -H -f 0 -v >/home/guido/mitdb/csv/102.csv\n",
      "rdann -r 102 -f 0 -a atr -v >/home/guido/mitdb/csv/102annotations.txt\n",
      "rdsamp -r 201 -c -H -f 0 -v >/home/guido/mitdb/csv/201.csv\n",
      "rdann -r 201 -f 0 -a atr -v >/home/guido/mitdb/csv/201annotations.txt\n",
      "rdsamp -r 207 -c -H -f 0 -v >/home/guido/mitdb/csv/207.csv\n",
      "rdann -r 207 -f 0 -a atr -v >/home/guido/mitdb/csv/207annotations.txt\n",
      "rdsamp -r 100 -c -H -f 0 -v >/home/guido/mitdb/csv/100.csv\n",
      "rdann -r 100 -f 0 -a atr -v >/home/guido/mitdb/csv/100annotations.txt\n",
      "rdsamp -r 105 -c -H -f 0 -v >/home/guido/mitdb/csv/105.csv\n",
      "rdann -r 105 -f 0 -a atr -v >/home/guido/mitdb/csv/105annotations.txt\n",
      "rdsamp -r 234 -c -H -f 0 -v >/home/guido/mitdb/csv/234.csv\n",
      "rdann -r 234 -f 0 -a atr -v >/home/guido/mitdb/csv/234annotations.txt\n",
      "rdsamp -r 103 -c -H -f 0 -v >/home/guido/mitdb/csv/103.csv\n",
      "rdann -r 103 -f 0 -a atr -v >/home/guido/mitdb/csv/103annotations.txt\n",
      "rdsamp -r 116 -c -H -f 0 -v >/home/guido/mitdb/csv/116.csv\n",
      "rdann -r 116 -f 0 -a atr -v >/home/guido/mitdb/csv/116annotations.txt\n",
      "rdsamp -r 220 -c -H -f 0 -v >/home/guido/mitdb/csv/220.csv\n",
      "rdann -r 220 -f 0 -a atr -v >/home/guido/mitdb/csv/220annotations.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n",
      "sh: 1: rdsamp: not found\n",
      "sh: 1: rdann: not found\n"
     ]
    }
   ],
   "source": [
    "from os import listdir, mkdir, system\n",
    "from os.path import isfile, isdir, join, exists\n",
    "\n",
    "\n",
    "def convert_mitdb_2_csv():\n",
    "    home_dir = os.path.expanduser(\"~\")\n",
    "    dir = os.path.join(home_dir, \"mitdb\")\n",
    "    # Create folder\n",
    "    csv = dir + \"/csv/\"\n",
    "    if not exists(csv):\n",
    "        mkdir(csv)\n",
    "\n",
    "    records = [\n",
    "        f for f in listdir(dir) if isfile(join(dir, f)) if (f.find(\".dat\") != -1)\n",
    "    ]\n",
    "    # print records\n",
    "\n",
    "    for r in records:\n",
    "\n",
    "        command = \"rdsamp -r \" + r[:-4] + \" -c -H -f 0 -v >\" + csv + r[:-4] + \".csv\"\n",
    "        print(command)\n",
    "        system(command)\n",
    "\n",
    "        command_annotations = (\n",
    "            \"rdann -r \"\n",
    "            + r[:-4]\n",
    "            + \" -f 0 -a atr -v >\"\n",
    "            + csv\n",
    "            + r[:-4]\n",
    "            + \"annotations.txt\"\n",
    "        )\n",
    "        print(command_annotations)\n",
    "        system(command_annotations)\n",
    "\n",
    "\n",
    "convert_mitdb_2_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipping started...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/guido/physionet2020/ptb-xl/classification-of-12-lead-ecgs-the-physionetcomputing-in-cardiology-challenge-2020-1.0.2.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating directory for physionet2020 data.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(path)\n\u001b[0;32m---> 13\u001b[0m data_info \u001b[38;5;241m=\u001b[39m \u001b[43mload_physionet2020\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpath_to_zip\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpath_to_unzip\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mdelete_zip\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/physioex/lib/python3.10/site-packages/ecglib/data/load_datasets.py:137\u001b[0m, in \u001b[0;36mload_physionet2020\u001b[0;34m(download, path_to_zip, path_to_unzip, delete_zip, selected_datasets)\u001b[0m\n\u001b[1;32m    130\u001b[0m selected_datasets_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    131\u001b[0m     [\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassification-of-12-lead-ecgs-the-physionetcomputing-in-cardiology-challenge-2020-1.0.2/training/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    133\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m selected_datasets\n\u001b[1;32m    134\u001b[0m     ]\n\u001b[1;32m    135\u001b[0m )\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnzipping started...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 137\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_to_zip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclassification-of-12-lead-ecgs-the-physionetcomputing-in-cardiology-challenge-2020-1.0.2.zip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m zip_ref:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m member \u001b[38;5;129;01min\u001b[39;00m tqdm(zip_ref\u001b[38;5;241m.\u001b[39minfolist(), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m member\u001b[38;5;241m.\u001b[39mfilename\u001b[38;5;241m.\u001b[39mstartswith(selected_datasets_paths):\n",
      "File \u001b[0;32m~/miniconda3/envs/physioex/lib/python3.10/zipfile.py:1251\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1251\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilemode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m   1253\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/guido/physionet2020/ptb-xl/classification-of-12-lead-ecgs-the-physionetcomputing-in-cardiology-challenge-2020-1.0.2.zip'"
     ]
    }
   ],
   "source": [
    "from ecglib.data import load_physionet2020, EcgRecord\n",
    "import os\n",
    "from loguru import logger\n",
    "\n",
    "path = \"~/physionet2020/ptb-xl/\"\n",
    "path = os.path.expanduser(path)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    logger.info(\"Creating directory for physionet2020 data.\")\n",
    "    os.makedirs(path)\n",
    "\n",
    "\n",
    "data_info = load_physionet2020(path_to_zip=path, path_to_unzip=path, delete_zip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m data_info:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(record)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "for record in data_info:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SJfAlIo-CZh9"
   },
   "outputs": [],
   "source": [
    "# setup the working directory\n",
    "import os\n",
    "\n",
    "working_dir = \"/content/drive/MyDrive/Thesis\"\n",
    "os.chdir(working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 0, 1, 2, 2]), array([0, 1, 1, 0, 2]))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "m = np.array([[1, 1, 0], [0, 1, 0], [1, 0, 1]])\n",
    "print(np.where(m == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jZKvO9KdCug5",
    "outputId": "49fe9f93-2b79-464f-ef0d-72896d4155df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'physioex' already exists and is not an empty directory.\n",
      "/content/drive/MyDrive/Thesis/physioex\n"
     ]
    }
   ],
   "source": [
    "# follow the guide on https://guidogagl.github.io/physioex/\n",
    "# clone your forked repo\n",
    "!git clone https://github.com/guidogagl/physioex.git\n",
    "%cd physioex\n",
    "\n",
    "!git pull origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pGa_PZZMDjIN"
   },
   "outputs": [],
   "source": [
    "# install the library in development mode\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bdDv0QZWDnS2"
   },
   "outputs": [],
   "source": [
    "# train the model proposed by chambon2018 on the DREEM dataset ( DODH version )\n",
    "!train -e chambon2018 --dataset dreem --version dodh -vci 30 --sequence_lenght 3 -nj 2 --checkpoint \"models/cel/chambon2018/seqlen=3/dreem/dodh/\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNB8kptHbY8lNXyhBh/0TWM",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
